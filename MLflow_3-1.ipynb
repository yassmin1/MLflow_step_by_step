{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yassmin1/MLflow_step_by_step/blob/main/MLflow_3-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ **Module 3.1: Custom PythonModel for Real-World Use** notebook is ready.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Assessment: Custom PythonModel for Real-World Use\n",
        "\n",
        "### üìò Multiple Choice (Answers in **bold**)\n",
        "\n",
        "**1. What does `load_context()` allow your custom `PythonModel` to do?**\n",
        "A. Set model parameters manually\n",
        "**B. Load external artifacts like pipelines or tokenizers** ‚úÖ\n",
        "C. Tune hyperparameters dynamically\n",
        "D. Fetch model inputs from MLflow UI\n",
        "\n",
        "---\n",
        "\n",
        "**2. In the custom model example, what happens if a negative value appears in the input?**\n",
        "A. An exception is raised\n",
        "**B. The model returns -1 for each row** ‚úÖ\n",
        "C. The model returns NaN\n",
        "D. Prediction is skipped for that row\n",
        "\n",
        "---\n",
        "\n",
        "**3. What is the correct method to store files like pickled pipelines in MLflow?**\n",
        "A. `mlflow.save_model()`\n",
        "B. `mlflow.log_file()`\n",
        "**C. `mlflow.pyfunc.log_model(..., artifacts={...})`** ‚úÖ\n",
        "D. `mlflow.register_artifact()`\n",
        "\n",
        "---\n",
        "\n",
        "**4. Why would you use a custom `pyfunc` model over a standard flavor like `mlflow.sklearn`?**\n",
        "A. To reduce log file size\n",
        "B. To skip preprocessing\n",
        "**C. To wrap custom logic such as input checks, transformation, or ensemble voting** ‚úÖ\n",
        "D. To avoid using artifacts\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úèÔ∏è Short Answer\n",
        "\n",
        "**5. What is the advantage of using a pipeline + custom logic in a `PythonModel`?**\n",
        "*Combines both feature engineering and model prediction logic in one deployable unit. This ensures consistency between training and inference environments.*\n",
        "\n",
        "---\n",
        "\n",
        "**6. How do artifacts make your MLflow model more powerful and reusable?**\n",
        "*Artifacts allow models to include reusable components like encoders, scalers, vocabularies, or other external files necessary for prediction.*\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Mini Project\n",
        "\n",
        "**7. Task:**\n",
        "\n",
        "* Modify the example so that instead of rejecting negative values, it replaces them with zero\n",
        "* Log and test the modified model\n",
        "* Use `mlflow.pyfunc.load_model()` and predict on `DataFrame([[10, -10], [0, 100]])`\n",
        "* Output the predictions\n",
        "\n",
        "---\n",
        "\n",
        "Would you like me to proceed with **Module 3.2: Packaging Pre/Post Processing**, including its assessment?\n"
      ],
      "metadata": {
        "id": "6HNM1pRBiX-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìì Module 3.2: Packaging Pre/Post Processing with MLflow\n",
        "# Goal: Bundle preprocessing and postprocessing into a single deployable MLflow model\n",
        "\n",
        "# ‚úÖ Step 1: Install required packages\n",
        "!pip install -q mlflow scikit-learn pandas joblib\n",
        "\n",
        "# ‚úÖ Step 2: Import required libraries\n",
        "import mlflow.pyfunc\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# ‚úÖ Step 3: Create preprocessing + model pipeline\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ Step 4: Save pipeline to disk\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "joblib.dump(pipeline, \"artifacts/iris_pipeline.pkl\")\n",
        "\n",
        "# ‚úÖ Step 5: Define PythonModel with postprocessing (convert probs to labels)\n",
        "class WrappedPipelineModel(mlflow.pyfunc.PythonModel):\n",
        "    def load_context(self, context):\n",
        "        self.pipeline = joblib.load(context.artifacts[\"pipeline_file\"])\n",
        "\n",
        "    def predict(self, context, model_input):\n",
        "        probs = self.pipeline.predict_proba(model_input)\n",
        "        return pd.DataFrame({\n",
        "            \"predicted_label\": probs.argmax(axis=1),\n",
        "            \"probability\": probs.max(axis=1)\n",
        "        })\n",
        "\n",
        "# ‚úÖ Step 6: Log the wrapped model with MLflow\n",
        "model_path = \"iris_wrapped_model\"\n",
        "artifacts = {\"pipeline_file\": \"artifacts/iris_pipeline.pkl\"}\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.pyfunc.log_model(\n",
        "        artifact_path=model_path,\n",
        "        python_model=WrappedPipelineModel(),\n",
        "        artifacts=artifacts\n",
        "    )\n",
        "    print(\"‚úÖ Pipeline with preprocessing and postprocessing logged.\")\n",
        "\n",
        "# ‚úÖ Step 7: Load and test the model\n",
        "loaded = mlflow.pyfunc.load_model(f\"runs:/{mlflow.last_active_run().info.run_id}/{model_path}\")\n",
        "test_input = pd.DataFrame(X_test, columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
        "predictions = loaded.predict(test_input)\n",
        "print(\"\\nüîÆ Predictions with label and probability:\")\n",
        "print(predictions.head())"
      ],
      "metadata": {
        "id": "2BqDM1qxihUl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}