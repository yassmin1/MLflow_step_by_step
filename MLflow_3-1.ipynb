{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yassmin1/MLflow_step_by_step/blob/main/MLflow_3-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNM1pRBiX-o"
      },
      "source": [
        "‚úÖ **Module 3.1: Custom PythonModel for Real-World Use**\n",
        "Here's a simple yet detailed breakdown of the learning goal:\n",
        "\n",
        "## üéØ **Goal Expanded**\n",
        "\n",
        "### **Packaging Pre/Post Processing with MLflow**\n",
        "\n",
        "* **What it means:**\n",
        "  Combining all the steps involved in data processing‚Äîpreprocessing (transforming raw data before predictions) and postprocessing (transforming model outputs)‚Äîinto a single, unified model package using MLflow.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **Why This Matters:**\n",
        "\n",
        "When deploying machine learning models, it's crucial to replicate the exact steps taken during training at prediction time. This includes:\n",
        "\n",
        "* **Preprocessing:** Steps like scaling features, encoding categories, and handling missing values.\n",
        "* **Prediction:** Using the trained model to make predictions.\n",
        "* **Postprocessing:** Steps like converting numerical predictions into human-readable labels, applying thresholds, or formatting outputs.\n",
        "\n",
        "Bundling these together ensures your model predictions are consistent, accurate, and reliable across different deployment environments.\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ **Detailed Steps to Achieve This:**\n",
        "\n",
        "1. **Create a Preprocessing Pipeline**\n",
        "\n",
        "   * Use tools like Scikit-learn‚Äôs pipelines to standardize and automate preprocessing.\n",
        "\n",
        "   ```python\n",
        "   from sklearn.pipeline import Pipeline\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   pipeline = Pipeline([\n",
        "       ('scaler', StandardScaler()),\n",
        "       ('model', LogisticRegression())\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "2. **Define Postprocessing Logic**\n",
        "\n",
        "   * Include any required logic that processes predictions after the model runs. For example, converting class probabilities into labels:\n",
        "\n",
        "   ```python\n",
        "   def postprocess(pred_probs):\n",
        "       return [\"positive\" if prob > 0.5 else \"negative\" for prob in pred_probs]\n",
        "   ```\n",
        "\n",
        "3. **Combine Using MLflow‚Äôs PythonModel**\n",
        "\n",
        "   * Define a custom MLflow PythonModel that encapsulates both preprocessing and postprocessing:\n",
        "\n",
        "   ```python\n",
        "   import mlflow.pyfunc\n",
        "\n",
        "   class CustomModel(mlflow.pyfunc.PythonModel):\n",
        "       def load_context(self, context):\n",
        "           self.pipeline = joblib.load(context.artifacts[\"pipeline\"])\n",
        "       \n",
        "       def predict(self, context, model_input):\n",
        "           preprocessed_input = self.pipeline[:-1].transform(model_input)\n",
        "           pred_probs = self.pipeline[-1].predict_proba(preprocessed_input)[:, 1]\n",
        "           return postprocess(pred_probs)\n",
        "   ```\n",
        "\n",
        "4. **Log Everything Together**\n",
        "\n",
        "   * Log this bundled model to MLflow:\n",
        "\n",
        "   ```python\n",
        "   mlflow.pyfunc.log_model(\n",
        "       artifact_path=\"bundled_model\",\n",
        "       python_model=CustomModel(),\n",
        "       artifacts={\"pipeline\": \"pipeline.pkl\"}\n",
        "   )\n",
        "   ```\n",
        "\n",
        "5. **Deploy as One Unit**\n",
        "\n",
        "   * Now, you can deploy and serve this complete pipeline as a single REST API or Docker image.\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ **Benefits of Packaging Pre/Post Processing:**\n",
        "\n",
        "* **Consistency**: Ensures identical transformations during training and serving.\n",
        "* **Reproducibility**: Makes models easier to replicate across environments.\n",
        "* **Simplicity**: Reduces complexity during deployment, as you handle only one package instead of multiple separate scripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2BqDM1qxihUl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryass\\OneDrive\\Documents\\GitHub\\MLflow_learn\\.venv\\Lib\\site-packages\\mlflow\\pyfunc\\utils\\data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
            "  color_warning(\n",
            "2025/08/01 17:09:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/08/01 17:09:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Pipeline with preprocessing and postprocessing logged.\n",
            "\n",
            "üîÆ Predictions with label and probability:\n",
            "   predicted_label  probability\n",
            "0                1     0.875979\n",
            "1                0     0.964411\n",
            "2                2     0.997118\n",
            "3                1     0.759399\n",
            "4                1     0.752136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ryass\\OneDrive\\Documents\\GitHub\\MLflow_learn\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# üìì Module 3.2: Packaging Pre/Post Processing with MLflow\n",
        "# Goal: Bundle preprocessing and postprocessing into a single deployable MLflow model\n",
        "\n",
        "# ‚úÖ Step 1: Install required packages\n",
        "!pip install -q mlflow scikit-learn pandas joblib\n",
        "\n",
        "# ‚úÖ Step 2: Import required libraries\n",
        "import mlflow.pyfunc\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# ‚úÖ Step 3: Create preprocessing + model pipeline\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ Step 4: Save pipeline to disk\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "joblib.dump(pipeline, \"artifacts/iris_pipeline.pkl\")\n",
        "\n",
        "# ‚úÖ Step 5: Define PythonModel with postprocessing (convert probs to labels)\n",
        "class WrappedPipelineModel(mlflow.pyfunc.PythonModel):\n",
        "    def load_context(self, context):\n",
        "        self.pipeline = joblib.load(context.artifacts[\"pipeline_file\"])\n",
        "\n",
        "    def predict(self, context, model_input):\n",
        "        probs = self.pipeline.predict_proba(model_input)\n",
        "        return pd.DataFrame({\n",
        "            \"predicted_label\": probs.argmax(axis=1),\n",
        "            \"probability\": probs.max(axis=1)\n",
        "        })\n",
        "\n",
        "# ‚úÖ Step 6: Log the wrapped model with MLflow\n",
        "model_path = \"iris_wrapped_model\"\n",
        "artifacts = {\"pipeline_file\": \"artifacts/iris_pipeline.pkl\"}\n",
        "\n",
        "with mlflow.start_run():\n",
        "    mlflow.pyfunc.log_model(\n",
        "        artifact_path=model_path,\n",
        "        python_model=WrappedPipelineModel(),\n",
        "        artifacts=artifacts\n",
        "    )\n",
        "    print(\"‚úÖ Pipeline with preprocessing and postprocessing logged.\")\n",
        "\n",
        "# ‚úÖ Step 7: Load and test the model\n",
        "loaded = mlflow.pyfunc.load_model(f\"runs:/{mlflow.last_active_run().info.run_id}/{model_path}\")\n",
        "test_input = pd.DataFrame(X_test, columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
        "predictions = loaded.predict(test_input)\n",
        "print(\"\\nüîÆ Predictions with label and probability:\")\n",
        "print(predictions.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## üìù Assessment: Custom PythonModel for Real-World Use\n",
        "\n",
        "### üìò Multiple Choice (Answers in **bold**)\n",
        "\n",
        "**1. What does `load_context()` allow your custom `PythonModel` to do?**   \n",
        "A. Set model parameters manually   \n",
        "**B. Load external artifacts like pipelines or tokenizers** ‚úÖ   \n",
        "C. Tune hyperparameters dynamically   \n",
        "D. Fetch model inputs from MLflow UI   \n",
        "\n",
        "---\n",
        "\n",
        "**2. In the custom model example, what happens if a negative value appears in the input?**      \n",
        "A. An exception is raised      \n",
        "**B. The model returns -1 for each row** ‚úÖ      \n",
        "C. The model returns NaN      \n",
        "D. Prediction is skipped for that row      \n",
        "\n",
        "---\n",
        "\n",
        "**3. What is the correct method to store files like pickled pipelines in MLflow?**   \n",
        "A. `mlflow.save_model()`   \n",
        "B. `mlflow.log_file()   `\n",
        "**C. `mlflow.pyfunc.log_model(..., artifacts={...})`** ‚úÖ   \n",
        "D. `mlflow.register_artifact()`   \n",
        "\n",
        "---\n",
        "\n",
        "**4. Why would you use a custom `pyfunc` model over a standard flavor like `mlflow.sklearn`?**   \n",
        "A. To reduce log file size   \n",
        "B. To skip preprocessing   \n",
        "**C. To wrap custom logic such as input checks, transformation, or ensemble voting** ‚úÖ   \n",
        "D. To avoid using artifacts   \n",
        "   \n",
        "---\n",
        "\n",
        "### ‚úèÔ∏è Short Answer\n",
        "\n",
        "**5. What is the advantage of using a pipeline + custom logic in a `PythonModel`?**   \n",
        "*Combines both feature engineering and model prediction logic in one deployable unit. This ensures consistency between training and inference environments.*   \n",
        "\n",
        "---\n",
        "\n",
        "**6. How do artifacts make your MLflow model more powerful and reusable?**   \n",
        "*Artifacts allow models to include reusable components like encoders, scalers, vocabularies, or other external files necessary for prediction.*   \n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Mini Project\n",
        "\n",
        "**7. Task:**   \n",
        "\n",
        "* Modify the example so that instead of rejecting negative values, it replaces them with zero   \n",
        "* Log and test the modified model   \n",
        "* Use `mlflow.pyfunc.load_model()` and predict on `DataFrame([[10, -10], [0, 100]])`   \n",
        "* Output the predictions   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "scratchpad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
