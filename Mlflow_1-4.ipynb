{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPk/xH5FmVhr7OkAVUnXaB/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[" **Module 1.4: MLflow UI Deep Dive** is now ready. It walks learners through:\n","## üéØ **Learning Objectives**\n","\n","### 1Ô∏è‚É£ **Access and Inspect MLflow Runs Programmatically**\n","\n","* **What it means:**\n","  Using MLflow‚Äôs Python API to retrieve details of past runs, including metrics, parameters, and logged artifacts directly from code.\n","\n","* **Detailed Steps:**\n","\n","  * Import MLflow:\n","\n","    ```python\n","    import mlflow\n","    ```\n","  * Fetch runs as a DataFrame:\n","\n","    ```python\n","    runs_df = mlflow.search_runs(experiment_names=[\"my-experiment\"])\n","    print(runs_df.head())\n","    ```\n","  * Inspect specific parameters or metrics:\n","\n","    ```python\n","    runs_df[[\"run_id\", \"metrics.rmse\", \"params.alpha\"]]\n","    ```\n","\n","* **Why it matters:**\n","  Programmatic access allows automated analysis, easy comparison, and integration with other data-processing tools.\n","\n","---\n","\n","### 2Ô∏è‚É£ **Understand the Layout and Capabilities of the MLflow UI**\n","\n","* **What it means:**\n","  Familiarizing yourself with MLflow's graphical user interface, which provides an easy way to browse and manage experiments and runs visually.\n","\n","* **Detailed Explanation:**\n","  MLflow UI key sections:\n","\n","  * **Experiments:** Organized runs grouped by experiments.\n","  * **Runs:** Detailed view of parameters, metrics, artifacts, tags, timestamps.\n","  * **Comparison view:** Side-by-side comparison of multiple runs.\n","  * **Artifacts tab:** Access to model files, plots, or logs stored during runs.\n","\n","* **Why it matters:**\n","  Visual interaction makes managing, comparing, and understanding your ML experiments much easier and faster, particularly when you have numerous runs or complex data.\n","\n","---\n","\n","### 3Ô∏è‚É£ **Sort, Filter, and Compare Experiments Visually**\n","\n","* **What it means:**\n","  Using MLflow‚Äôs UI to quickly organize runs, filter by parameters or metrics, and visually compare experiment results.\n","\n","* **Detailed Steps:**\n","\n","  * **Sorting:** Click on column headers in MLflow UI to sort runs by metric (e.g., lowest RMSE).\n","  * **Filtering:** Enter queries in the filter box (e.g., `params.alpha = \"0.01\"`).\n","  * **Visual comparisons:** Use the comparison feature to show multiple run metrics side-by-side graphically.\n","\n","* **Why it matters:**\n","  Easy visual sorting and filtering significantly simplify the task of identifying the best models or experiment conditions.\n","\n","---\n","\n","### 4Ô∏è‚É£ **Export Results for Offline Analysis**\n","\n","* **What it means:**\n","  Downloading or exporting MLflow run data to files (e.g., CSV format) so you can analyze them outside the MLflow environment using tools like Excel, Pandas, or PowerBI.\n","\n","* **Detailed Steps:**\n","\n","  * Export runs programmatically to CSV:\n","\n","    ```python\n","    runs_df = mlflow.search_runs(experiment_names=[\"my-experiment\"])\n","    runs_df.to_csv(\"experiment_runs.csv\", index=False)\n","    ```\n","  * Download via MLflow UI:\n","\n","    * Use the \"Download CSV\" feature in the UI to get results manually.\n","\n","* **Why it matters:**\n","  Exporting data allows for deeper, customized analysis and easier sharing of experiment details with team members or stakeholders who prefer external analytics tools.\n","\n","\n"],"metadata":{"id":"ir_Miy2BpReR"}},{"cell_type":"code","source":["# üìì Module 1.4: MLflow UI Deep Dive (Local Use Only)\n","# Goal: Learn how to explore, analyze, and compare runs using the MLflow Tracking UI.\n","\n","# ‚úÖ Step 1: Install MLflow if not already installed\n","!pip install -q mlflow\n","\n","# ‚úÖ Step 2: Import necessary modules\n","import mlflow\n","import pandas as pd\n","\n","# ‚úÖ Step 3: Set the experiment name\n","experiment_name = \"autologging-random-forest\"\n","mlflow.set_experiment(experiment_name)\n","\n","# ‚úÖ Step 4: Programmatically explore the experiment\n","# Load all runs under this experiment\n","runs_df = mlflow.search_runs(experiment_names=[experiment_name])\n","\n","# Show key columns\n","display_cols = [\"run_id\", \"metrics.training_score\", \"metrics.test_rmse\", \"params.max_depth\"]\n","print(\"Available runs in experiment:\")\n","display(runs_df[display_cols].sort_values(\"metrics.test_rmse\"))\n","\n","# ‚úÖ Step 5: Launch MLflow Tracking UI (locally only)\n","# NOTE: This command won't work in hosted notebooks like Colab.\n","# Run this command from your terminal or local Jupyter notebook.\n","#\n","# !mlflow ui\n","#\n","# Then open your browser and navigate to: http://localhost:5000\n","#\n","# From the UI, you can:\n","# - Select experiments\n","# - View and compare run metrics visually\n","# - Download artifacts\n","# - Transition models (if using registry)\n","\n","# ‚úÖ Step 6: Optional - Export results\n","# Export the runs DataFrame to CSV for offline analysis\n","runs_df.to_csv(\"mlflow_run_comparison.csv\", index=False)\n","print(\"Run data exported to mlflow_run_comparison.csv\")\n"],"metadata":{"id":"4rt6LtGepGN9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üìù Assessment: MLflow UI Deep Dive\n","\n","### üìò Multiple Choice (Choose the best answer)\n","\n","**1. What is the default URL to access the MLflow Tracking UI when launched locally?**   \n","A. [http://localhost:3000](http://localhost:3000)   \n","**B. [http://localhost:5000](http://localhost:5000)** ‚úÖ   \n","C. [http://127.0.0.1:8888](http://127.0.0.1:8888)   \n","D. [http://mlflow.localhost/ui](http://mlflow.localhost/ui)   \n","\n","---\n","\n","**2. Which MLflow command launches the UI from the command line?**   \n","A. `mlflow run`   \n","**B. `mlflow ui`** ‚úÖ   \n","C. `mlflow open`   \n","D. `mlflow start`   \n","\n","---\n","\n","**3. What can you do from the MLflow UI? (Select the most complete answer)**   \n","A. View logged metrics only   \n","B. Launch models into production directlyv   \n","**C. Compare runs, download artifacts, inspect metrics/params, and register models** ‚úÖ   \n","D. Execute Python scripts in runs   \n","\n","---\n","\n","**4. Which function allows you to retrieve past run data programmatically in MLflow?**   \n","A. `mlflow.get_runs()`   \n","B. `mlflow.experiments.get()`   \n","**C. `mlflow.search_runs()`** ‚úÖ   \n","D. `mlflow.list_models()`   \n","\n","---\n","\n","### ‚úèÔ∏è Short Answer   \n","\n","**5. How does the MLflow UI help in comparing different model runs?**   \n","*Explain sorting, metric charts, side-by-side comparisons.*   \n","\n","---\n","\n","**6. In what situations would exporting runs to CSV be useful?**   \n","*Hint: Think about sharing, offline analysis, or integration with reporting tools.*   \n","\n","---\n","\n","### üß™ Mini Project   \n","\n","**7. Task:**   \n","After completing several training runs with different hyperparameters:   \n","\n","* Use `mlflow.search_runs()` to fetch all runs in an experiment   \n","* Sort the runs based on a specific metric (e.g., `rmse`)   \n","* Export the top 3 performing runs to a CSV file   \n","* *(Optional)*: Open MLflow UI locally and take a screenshot of the run    comparison view   \n"],"metadata":{"id":"Tl2Akd1ZpyFZ"}}]}